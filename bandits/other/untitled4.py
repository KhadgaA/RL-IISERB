# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mfhmuHgIdfZgVzwTAKt3wGT4hKX6GeTQ
"""

"""
multi-armed bandit problem
"""

import numpy as np 

class bandit_env():
    """
    Initialize the multi-arm bandit environment.
    :params:
    r_mean: takes a list of reward mean
    r_stddev: takes a list of reward standard deviation
    """
    def __init__(self, r_mean, r_stddev):
        if len(r_mean) != len(r_stddev):
            raise ValueError("Reward distribution parameters (mean and variance) must be of the same length")

        if any(r <= 0 for r in r_stddev):
            raise ValueError("Standard deviation in rewards must all be greater than 0")

        self.n = len(r_mean)
        self.r_mean = r_mean
        self.r_stddev = r_stddev

    def pull(self, index_arm):
        """
        Performs the action of pulling the arm/lever of the selected bandit
        :inputs:
        index_arm: the index of the arm/level to be pulled
        :outputs:
        reward: the reward obtained by pulling tht arm (sampled from their corresponding Gaussian distribution)
        """
        reward = np.random.normal(self.r_mean[index_arm], self.r_stddev[index_arm])
        return reward

b1=bandit_env([2.5, -3.5, 1.0, 5.0, -2.5],[0.33, 1.0, 0.66, 1.98, 1.65])
#creatin object b1 with class bandit_env to run algorithm
import numpy as np
import random 
#arm selection: list of which arm of the five (i.e 0,1,2,3,4) was selected(it will be a lis of 1000 elements)
arm_selection=[]
#reward_list: as the name suggests it records all rewards of thousand selections
reward_list=[]

list=[0,0,0,0,0]
for t in range(1000):
  all_indexes = [] 
  for i in range(0, len(list)):
    if list[i] == max(list):
      all_indexes.append(i)

  index_arm=random.choice(all_indexes)
  arm_selection.append(index_arm)
  action_count=0
  list1=[]
  for x in range(len(arm_selection)):    
    list1.append(arm_selection[x]==index_arm)
    if list1[x]==True:
      action_count+=1
    else:
      continue
 

  n=action_count

  reward_list.append(b1.pull(index_arm))
  list[index_arm]= list[index_arm] + (reward_list[n]- list[index_arm])/n

arm_selection=[7,7,7,3,5]
action_count=0
index_arm =7
list1=[]
for x in range(len(arm_selection)):
  list1.append(arm_selection[x]==index_arm)
  if list1==True:
    action_count+=1

action_count=0
arm_selection=[2,3,4,5,3]
index_arm=3
list1=[]
for x in range(len(arm_selection)):
  list1.append(arm_selection[x]==index_arm)
  if list1[x]==True:
    action_count+=1
  else:
    continue

list=[0,0,0,1,0]
all_indexes = [] 
for i in range(0, len(list)):
  if list[i] == max(list):
    all_indexes.append(i)
index_arm=random.choice(all_indexes)
index_arm

b1=bandit_env([2.5, -3.5, 1.0, 5.0, -2.5],[0.33, 1.0, 0.66, 1.98, 1.65])
#creatin object b1 with class bandit_env to run algorithm
import numpy as np
import random 
#arm selection: list of which arm of the five (i.e 0,1,2,3,4) was selected(it will be a lis of 1000 elements)
arm_selection=[]
#reward_list: as the name suggests it records all rewards of thousand selections
reward_list=[]

list=[0,0,0,0,0]
for t in range(1000):
  all_indexes = [] 
  for i in range(0, len(list)):
    if list[i] == max(list):
      all_indexes.append(i)

  index_arm=random.choice(all_indexes)
  arm_selection.append(index_arm)
  action_count=0
  
  for x in range(len(arm_selection)):    
    if arm_selection[x]==index_arm:      
      action_count+=1
    else:
      continue
  n=action_count
  reward_list.append(b1.pull(index_arm))
  list[index_arm]= list[index_arm] + (reward_list[n]- list[index_arm])/n

list[index_arm]= list[index_arm] + (reward_list[n]- list[index_arm])/n

len(reward_list)



len(arm_selection)

list[index_arm]= list[index_arm] + (reward_list[n]- list[index_arm])/n
  list[index_arm]

