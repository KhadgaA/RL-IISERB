{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93833dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1affc1e",
   "metadata": {},
   "source": [
    "__Policy Iteration__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d12b9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State : Optimal Policy, Convergence time = 1\n",
      "Hostel : Eating\n",
      "Academic Building : Eating\n",
      "Canteen : Eating\n"
     ]
    }
   ],
   "source": [
    "States = np.array([\"Hostel\", \"Academic Building\", \"Canteen\"])\n",
    "Actions = np.array([\"Eating\", \"AttendingClass\"])\n",
    "Reward = np.array([-1, 3, 1])\n",
    "\n",
    "P = np.array(\n",
    "    [[[0, 0, 1], [0.5, 0.5, 0]],\n",
    "    [[0, 0.2, 0.8], [0, 0.7, 0.3]],\n",
    "    [[0, 0, 1], [0.3, 0.6, 0.1]],    \n",
    "    ])\n",
    "\n",
    "Vs = np.zeros(3)  # stores best action value of each state\n",
    "gamma = 0.9\n",
    "count = 0\n",
    "policy = np.random.randint(low=2, size=3)  # 2 bec we have 2 actions only\n",
    "Va = policy   # stores best action index of each state\n",
    "\n",
    "# The Policy iteration loop\n",
    "for time in range(100):\n",
    "    # Policy Evaluation\n",
    "    V = np.zeros(3)\n",
    "    for s in range(len(States)):\n",
    "        maxa = []\n",
    "        for a in range(len(Actions)):\n",
    "            t = P[s][a]\n",
    "            act = 0\n",
    "            for index,element in enumerate(t):\n",
    "                if element != 0:\n",
    "                    act = act+(t[index]*(Reward[index] + gamma*V[index]))\n",
    "\n",
    "            maxa.append(act)\n",
    "\n",
    "        V[s] = maxa[np.argmax(maxa)]\n",
    "    \n",
    "    # Policy Improvment\n",
    "    Vaai = np.zeros(3)\n",
    "    for st in range(len(States)):\n",
    "        maxaa = []\n",
    "        for aa in range(len(Actions)):\n",
    "            ta = P[st][aa]\n",
    "            acta = 0\n",
    "            for indexi,elemente in enumerate(ta):\n",
    "                if elemente != 0:\n",
    "                    acta = acta+(ta[indexi]*(Reward[indexi] + gamma*V[indexi]))\n",
    "\n",
    "            maxaa.append(acta)\n",
    "\n",
    "        Vaai[s] = np.argmax(maxaa)\n",
    "        \n",
    "    if not (Va - Vaai).any():\n",
    "        count += 1\n",
    "        if count == 2:\n",
    "            break\n",
    "    else:\n",
    "        count = 0\n",
    "\n",
    "    Va = Vaai\n",
    "    Vs = V\n",
    "    \n",
    "print(f\"State : Optimal Policy, Convergence time = {time}\", end=\"\\n\")\n",
    "for ie, statet in enumerate(States):\n",
    "    stateiv = statet\n",
    "    Optimal_Action_Indexi = int(Va[ie])\n",
    "    Optimal_Policy = Actions[Optimal_Action_Indexi]\n",
    "    print(f\"{stateiv} : {Optimal_Policy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bb895a",
   "metadata": {},
   "source": [
    "__Discuss the results obtained from policy iteration and value iteration__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6100c502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
